var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ADAPT","category":"page"},{"location":"#ADAPT","page":"Home","title":"ADAPT","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ADAPT.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Core","page":"Home","title":"Core","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [\n    ADAPT,\n]","category":"page"},{"location":"#ADAPT.AbstractAnsatz","page":"Home","title":"ADAPT.AbstractAnsatz","text":"AbstractAnsatz{F,G}\n\nAn image of an ADAPT protocol in a frozen state.\n\nThe type is so named because the most basic possible such image     consists of just the generators and parameters of the ansatz thus far selected,     but richer variants of ADAPT will have richer states.\n\nFor example, a version of ADAPT which carries information     on the inverse Hessian across ADAPT iterations     would need to operate on an ansatz type which includes the inverse Hessian.\n\nNevertheless, every sub-type of AbstractAnsatz implements the AbstractVector interface,     where elements are pairs (generator => parameter).\n\nSo, for example, an ansatz maintaining an inverse Hessian would need     to override push! insert!, etc. to ensure the dimension of the Hessian matches.\n\nType Parameters\n\nF: the number type of the parameters (usually Float64)\nG: the subtype of Generator\n\nImplementation\n\nSub-types must implement the following methods:\n\n__get__generators(::AbstractAnsatz{F,G})::Vector{G}\n__get__parameters(::AbstractAnsatz{F,G})::Vector{F}\n__get__optimized(::AbstractAnsatz{F,G})::Ref{Bool}\n__get__converged(::AbstractAnsatz{F,G})::Ref{Bool}\n\nEach of these is expected to simply retrieve an attribute of the struct. You can call them whatever you'd like, but functionally, here's what they mean:\n\ngenerators::Vector{G}: the sequence of generators\nparameters::Vector{F}: the corresponding sequence of parameters\nNote that these vectors will be mutated and resized as needed.\noptimized::Ref{Bool}: a flag indicating that the current parameters are optimal\nconverged::Ref{Bool}: a flag indicating that the current generators are optimal\nNote that these must be of type Ref, so their values can be toggled as needed.\n\nIn addition, there must be a compatible implementation for each of:\n\npartial(   index::Int,   ansatz::AbstractAnsatz,   observable::Observable,   reference::QuantumState, )\ncalculate_score(   ::AbstractAnsatz,   ::AdaptProtocol,   ::Generator,   ::Observable,   ::QuantumState, )::Score\nadapt!(   ::AbstractAnsatz,   ::Trace,   ::AdaptProtocol,   ::GeneratorList,   ::Observable,   ::QuantumState,   ::CallbackList, )\noptimize!(   ::AbstractAnsatz,   ::Trace,   ::OptimizationProtocol,   ::Observable,   ::QuantumState,   ::CallbackList, )\n\nThat said, most basic implementations of these methods are defined for abstract ansatze,     so you oughtn't need to worry about them.\n\nPlease see individual method documentation for details.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.AbstractCallback","page":"Home","title":"ADAPT.AbstractCallback","text":"AbstractCallback\n\nA function to be called at each adapt iteration, or vqe iteration, or both.\n\nCommon Examples\n\nTracers: update the running trace with information passed in data\nPrinters: display the information passed in data to the screen or to a file\nStoppers: flag the ADAPT state as converged, based on some condition\n\nIn particular, the standard way to converge an adapt run is to include a ScoreStopper. Otherwise, the run will keep adding parameters until every score is essentially zero.\n\nMore details can be found in the Callbacks module,     where many standard callbacks are already implemented.\n\nImplementation\n\nCallbacks are implemented as callable objects, with two choices of method header     (one for adaptations, one for optimization iterations).\n\n(::AbstractCallback)(   ::Data,   ::AbstractAnsatz,   ::Trace,   ::AdaptProtocol,   ::GeneratorList,   ::Observable,   ::QuantumState, )\n(::AbstractCallback)(   ::Data,   ::AbstractAnsatz,   ::Trace,   ::OptimizationProtocol,   ::Observable,   ::QuantumState, )\n\nIf your callback is only meant for adaptations,     simply do not implement the method for optimizations. (Behind the scenes, every AbstractCallback has default implementations for both methods,     which just don't do anything.)\n\nPrecisely what data is contained within the data depends on the protocol. For example, the ScoreStopper expects to find the key :scores,     whose value is a ScoreList, one score for each pool operator. Generally, the callback should assume data has whatever it needs,     and if it doesn't, that means this callback is incompatible with the given protocol. That said, see the Callbacks module for some standard choices.\n\nThe callback is free to mutate the ansatz. For example, the ScoreStopper signals a run should end by calling set_converged!. But, if the callback wants to signal the run should end in an UN-converged state,     it should simply return true.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.AbstractCallback-Tuple{Dict{Symbol, Any}, AbstractAnsatz, Dict{Symbol, Any}, AdaptProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.AbstractCallback","text":"(::AbstractCallback)(\n    ::Data,\n    ::AbstractAnsatz,\n    ::Trace,\n    ::AdaptProtocol,\n    ::GeneratorList,\n    ::Observable,\n    ::QuantumState,\n)\n\nCallback for adapt iterations, called immediately prior to the ansatz update.\n\nNote that the ansatz is already updated in the optimization callback,     but not in the adaptation callback.\n\nParameters\n\nAlmost all parameters for the adapt! method. See that method for details.\ndata: (replaces callbacks) additional calculations the ADAPT method has made   Keys depend on the protocol. See the Callbacks module for some standard choices.\n\nReturns\n\ntrue iff ADAPT should terminate, without updating ansatz\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.AbstractCallback-Tuple{Dict{Symbol, Any}, AbstractAnsatz, Dict{Symbol, Any}, OptimizationProtocol, Any, Any}","page":"Home","title":"ADAPT.AbstractCallback","text":"(::AbstractCallback)(\n    ::Data,\n    ::AbstractAnsatz,\n    ::Trace,\n    ::OptimizationProtocol,\n    ::Observable,\n    ::QuantumState,\n)\n\nCallback for optimization iterations, called AFTER ansatz update.\n\nNote that the ansatz is already updated in optimization callback,     but not in the adaptation callback.\n\nParameters\n\nAlmost all parameters for the optimize! method. See that method for details.\ndata: (replaces callbacks) additional calculations the optimization method has made   Keys depend on the protocol. See the Callbacks module for some standard choices.\n\nReturns\n\ntrue iff optimization should terminate\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.AdaptProtocol","page":"Home","title":"ADAPT.AdaptProtocol","text":"AdaptProtocol\n\nA distinctive protocol for adding new parameters after optimizing an initial ansatz.\n\nImplementation\n\nSub-types must implement the following method:\n\ntypeof_parameter(::AbstractAnsatz)::Type{<:Parameter}\n\nIn addition, new sub-types probably need to implement:\n\ncalculate_score(   ::AbstractAnsatz,   ::AdaptProtocol,   ::Generator,   ::Observable,   ::QuantumState, )::Score\nadapt!(   ::AbstractAnsatz,   ::Trace,   ::AdaptProtocol,   ::GeneratorList,   ::Observable,   ::QuantumState,   ::CallbackList, )\n\nFinally, new sub-types might be able to provide better implementations of:\n\ncalculate_scores(   ansatz::AbstractAnsatz,   ADAPT::AdaptProtocol,   pool::GeneratorList,   observable::Observable,   reference::QuantumState, )\n\nFor the most part, sub-types should be singleton objects, ie. no attributes. Arbitrary hyperparameters like gradient tolerance should be delegated to callbacks     as much as possible. It's okay to insist a particular callback always be included with your ADAPT protocol,     so long as you are clear in the documentation. That said, this rule is a \"style\" guideline, not a contract.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.CallbackList","page":"Home","title":"ADAPT.CallbackList","text":"CallbackList\n\nSemantic alias for a vector of callbacks.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Data","page":"Home","title":"ADAPT.Data","text":"Data\n\nSemantic alias for trace-worthy information from a single adapt or vqe iteration.\n\nYou'll never actually have to deal with this object     unless you are implementing your own protocol or callback.\n\nKeys can in principle be any Symbol at all. You can design your own protocols to fill the data,     and your own callbacks to use it. That said, see the Callbacks module for some standard choices.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Energy","page":"Home","title":"ADAPT.Energy","text":"Energy\n\nSemantic alias for the expectation value of an observable.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.EnergyList","page":"Home","title":"ADAPT.EnergyList","text":"EnergyList\n\nSemantic alias for a vector of energies.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Generator","page":"Home","title":"ADAPT.Generator","text":"Generator\n\nThe Union of any type that could be used as a pool operator.\n\nImplemented Types\n\nAny type at all can be used as a generator   if there is a compatible implementation   of the methods listed in the Implementation section.\n\nThe following types have implementations fleshed out in this library already:\n\nPauliOperators.Pauli: A single Pauli word\nPauliOperators.ScaledPauli: A single Pauli word, alongside some scaling coefficient\nPauliOperators.PauliSum: A Hermitian operator decomposed into the Pauli basis\nPauliOperators.ScaledPauliVector: Same but with a different internal data structure\nFor each of the above,     the generator G generates the unitary exp(-iθG). Hermiticity in G is not enforced, so be careful when constructing your pool operators.\n\nImplementation\n\nThis list should be extended as new sub-types are implemented.\n\nNew sub-types probably need to implement:\n\nevolve_state!(   ::Generator,   ::Parameter,   ::QuantumState, )\n\nIn addition, new sub-types might be able to provide better implementations of:\n\ncalculate_scores(   ansatz::AbstractAnsatz,   adapt::AdaptProtocol,   pool::GeneratorList,   observable::Observable,   reference::QuantumState, )\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.GeneratorList","page":"Home","title":"ADAPT.GeneratorList","text":"GeneratorList\n\nSemantic alias for a vector of generators.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Observable","page":"Home","title":"ADAPT.Observable","text":"Observable\n\nThe Union of any type that could define a cost function.\n\nThe type is so named because the typical cost-function is the expecation value     of a Hermitian operator, aka a quantum observable.\n\nImplemented Types\n\nAny type at all can be used as a generator   if there is a compatible implementation   of the methods listed in the Implementation section.\n\nThe following types have implementations fleshed out in this library already:\n\nPauliOperators.Pauli: A single Pauli word\nPauliOperators.ScaledPauli: A single Pauli word, alongside some scaling coefficient\nPauliOperators.PauliSum: A Hermitian operator decomposed into the Pauli basis\nPauliOperators.ScaledPauliVector: Same but with a different internal data structure\nFor each of the above,     the evaluation of H with respect to a quantum state |Ψ⟩ is ⟨Ψ|H|Ψ⟩.\n\nImplementation\n\nThis list should be extended as new sub-types are implemented.\n\nSub-types must implement the following method:\n\ntypeof_energy(::Observable)::Type{<:Energy}\n\nIn addition, new sub-types probably need to implement:\n\nevaluate(   ::Observable,   ::QuantumState, )::Energy\n\nFinally, new sub-types might be able to provide better implementations of:\n\ngradient!(   ansatz::AbstractAnsatz,   observable::Observable,   reference::QuantumState, )\ncalculate_scores(   ansatz::AbstractAnsatz,   adapt::AdaptProtocol,   pool::GeneratorList,   observable::Observable,   reference::QuantumState, )\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.OptimizationProtocol","page":"Home","title":"ADAPT.OptimizationProtocol","text":"OptimizationProtocol\n\nA distinctive protocol for refining parameters in an ansatz.\n\nImplementation\n\nSub-types must implement the following method:\n\noptimize!(   ::AbstractAnsatz,   ::Trace,   ::OptimizationProtocol,   ::Observable,   ::QuantumState,   ::CallbackList, )::Bool\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Parameter","page":"Home","title":"ADAPT.Parameter","text":"Parameter\n\nSemantic alias for the coefficient of a generator in an ansatz.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.ParameterList","page":"Home","title":"ADAPT.ParameterList","text":"ParameterList\n\nSemantic alias for a vector of parameters.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.QuantumState","page":"Home","title":"ADAPT.QuantumState","text":"QuantumState\n\nThe Union of any type that could define a quantum state.\n\nImplemented Types\n\nAny type at all can be used as a generator   if there is a compatible implementation   of the methods listed in the Implementation section.\n\nThe following types have implementations fleshed out in this library already:\n\nVector{<:Complex}: A dense statevector in the computational basis\nPauliOperators.SparseKetBasis:\nA dict mapping individual kets (PauliOperators.KetBitString) to their coefficients.\n\nImplementation\n\nThis list should be extended as new sub-types are implemented.\n\nThere must be a compatible implementation for each of:\n\nevolve_state!(   ::Generator,   ::Parameter,   ::QuantumState, )\nevaluate(   ::Observable,   ::QuantumState, )::Energy\ngradient!(   index::Int,   ansatz::AbstractAnsatz,   observable::Observable,   reference::QuantumState, )\ncalculate_scores(   ansatz::AbstractAnsatz,   adapt::AdaptProtocol,   pool::GeneratorList,   observable::Observable,   reference::QuantumState, )\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Score","page":"Home","title":"ADAPT.Score","text":"Score\n\nSemantic alias for the importance-factor of a pool operator,     eg. the expecation value of its commutator with an observable.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.ScoreList","page":"Home","title":"ADAPT.ScoreList","text":"ScoreList\n\nSemantic alias for a vector of scores.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Trace","page":"Home","title":"ADAPT.Trace","text":"Trace\n\nSemantic alias for a compact record of the entire ADAPT run.\n\nThe adapt!, optimize!, and run! functions require a Trace object,     which will be mutated throughout according to callbacks. Initialize an empty trace object by trace = Trace().\n\nKeys can in principle be any Symbol at all. You can design your own protocols to fill the data,     and your own callbacks to use it. That said, see the Callbacks module for some standard choices.\n\n\n\n\n\n","category":"type"},{"location":"#Base.Matrix-Tuple{Any, Int64, AbstractAnsatz}","page":"Home","title":"Base.Matrix","text":"Base.Matrix([F,] N::Int, ansatz::AbstractAnsatz)\n\nConstruct the unitary matrix representation of the action of an ansatz.\n\nParameters\n\nF: float type; the resulting matrix will be of type Matrix{Complex{F}}\nN: size of Hilbert space (ie. the number of rows in the matrix)\nansatz: the ansatz to be represented\n\n\n\n\n\n","category":"method"},{"location":"#Base.Matrix-Tuple{Any, Int64, Any, Number}","page":"Home","title":"Base.Matrix","text":"Base.Matrix([F,] N::Int, G::Generator, θ::Parameter)\n\nConstruct the unitary matrix representation of exp(-iθG).\n\nParameters\n\nF: float type; the resulting matrix will be of type Matrix{Complex{F}}\nN: size of Hilbert space (ie. the number of rows in the matrix)\nG: the generator of the matrix\nθ: a scalar coefficient multiplying the generator\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.adapt!-Tuple{AbstractAnsatz, Dict{Symbol, Any}, AdaptProtocol, AbstractVector, Any, Any, AbstractVector{<:AbstractCallback}}","page":"Home","title":"ADAPT.adapt!","text":"adapt!(\n    ::AbstractAnsatz,\n    ::Trace,\n    ::AdaptProtocol,\n    ::GeneratorList,\n    ::Observable,\n    ::QuantumState,\n    ::CallbackList,\n)\n\nUpdate an ansatz with a new generator(s) according to a given ADAPT protocol.\n\nTypically, each call to this function will select a single generator         whose score has the largest magnitude,     but richer variants of ADAPT will have richer behavior.\n\nFor example, an implementation of Tetris ADAPT would add multiple generators,     based on both the score and the \"disjointness\" of the generators     (which is something that implementation would have to define).\n\nParameters\n\nansatz: the ADAPT state\ntrace: a history of the ADAPT run thus far\nADAPT: the ADAPT protocol\npool: the list of generators to consider adding to the ansatz\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\ncallbacks: a list of functions to be called just prior to updating the ansatz\n\nReturns\n\na Bool, indicating whether or not an adaptation was made\n\nImplementation\n\nAny implementation of this method must be careful to obey the following contract:\n\nIf your ADAPT protocol decides the ansatz is already converged,      call set_converged!(ansatz, true) and return false,      without calling any callbacks.\nFill up a data dict with the expensive calculations you have to make anyway. See the default implementation for a minimal selection of data to include.\nBEFORE you actually update the ansatz,      call each callback in succession, passing it the data dict. If any callback returns true, return false without calling any more callbacks,      and without updating the ansatz.\nAfter all callbacks have been completed,  update the ansatz, call set_optimized!(ansatz, false), and return true.\n\nStandard operating procedure is to let callbacks do all the updates to trace. Thus, implementations of this method should normally ignore trace entirely     (except in passing it along to the callbacks). That said, this rule is a \"style\" guideline, not a contract.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.angles-Tuple{AbstractAnsatz}","page":"Home","title":"ADAPT.angles","text":"angles(::AbstractAnsatz)\n\nFetch all parameters in the ansatz as a vector.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.bind!-Union{Tuple{G}, Tuple{F}, Tuple{AbstractAnsatz{F, G}, AbstractVector{F}}} where {F, G}","page":"Home","title":"ADAPT.bind!","text":"bind!(::AbstractAnsatz, ::ParameterList)\n\nReplace all parameters in the ansatz.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.calculate_score-Tuple{AbstractAnsatz, AdaptProtocol, Any, Any, Any}","page":"Home","title":"ADAPT.calculate_score","text":"calculate_score(\n    ansatz::AbstractAnsatz,\n    ADAPT::AdaptProtocol,\n    generator::Generator,\n    H::Observable,\n    ψ0::QuantumState,\n)\n\nCalculate an \"importance\" score for a generator, with respect to a particular ADAPT state.\n\nParameters\n\nansatz: the ADAPT state\nADAPT: the ADAPT protocol. Different protocols may have different scoring strategies.\ngenerator: the generator to be scored\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\nscore: a scalar number, whose type is typeof_score(ADAPT)\n\nImplementation\n\nIn addition to implementing this method (which is mandatory),     strongly consider over-riding calculate_scores also,     to take advantage of compact measurement protocols,     or simply the fact that you should only need to evolve your reference state once.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.calculate_scores-Tuple{AbstractAnsatz, AdaptProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.calculate_scores","text":"calculate_scores(\n    ansatz::AbstractAnsatz,\n    ADAPT::AdaptProtocol,\n    pool::GeneratorList,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nCalculate a vector of scores for all generators in the pool.\n\nParameters\n\nansatz: the ADAPT state\nADAPT: the ADAPT protocol. Different protocols may have different scoring strategies.\npool: the list of generators to be scored\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\nscores: a vector whose elements are of type typeof_score(ADAPT).   scores[i] is the score for the generator pool[i]\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evaluate-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.evaluate","text":"evaluate(\n    ansatz::AbstractAnsatz,\n    H::Observable,\n    ψ0::QuantumState,\n)\n\nEvaluate a cost-function with respect to a particular ADAPT state.\n\nParameters\n\nansatz: the ADAPT state\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\nenergy: a scalar number, whose type is typeof_energy(observable)\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evaluate-Tuple{Any, Any}","page":"Home","title":"ADAPT.evaluate","text":"evaluate(\n    H::Observable,\n    Ψ::QuantumState,\n)\n\nEvaluate a cost-function with respect to a particular quantum state.\n\nParameters\n\nH: the object defining the cost-function\nΨ: the quantum state\n\nReturns\n\nenergy: a scalar number, whose type is typeof_energy(observable)\n\nImplementation\n\nTypically, the \"cost-function\" is the expectation value ⟨Ψ|H|Ψ⟩,     but different Observable types could have different definitions.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_state!-Tuple{AbstractAnsatz, Any}","page":"Home","title":"ADAPT.evolve_state!","text":"evolve_state!(\n    ansatz::AbstractAnsatz,\n    state::QuantumState,\n)\n\nApply an ansatz to the given quantum state, mutating and returning the state.\n\nBy default, generators with a lower index are applied to the state earlier. This means that the equation for |Ψ⟩ would list out generators in reverse order. Specific implementations of ansatze may override this behavior.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_state!-Tuple{Any, Number, Any}","page":"Home","title":"ADAPT.evolve_state!","text":"evolve_state!(\n    G::Generator,\n    θ::Parameter,\n    ψ::QuantumState,\n)\n\nRotate a quantum state ψ by an amount x about the axis defined by G,     mutating and returning ψ.\n\nImplementation\n\nTypically, the \"rotation\" is the unitary operator exp(-iθG),     but different Generator types could have different effects.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_state-Tuple{AbstractAnsatz, Any}","page":"Home","title":"ADAPT.evolve_state","text":"evolve_state(\n    ansatz::AbstractAnsatz,\n    reference::QuantumState,\n)\n\nCalculate the quantum state resulting from applying an ansatz to a given reference state.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_state-Tuple{Any, Number, Any}","page":"Home","title":"ADAPT.evolve_state","text":"evolve_state(\n    G::Generator,\n    θ::Parameter,\n    ψ::QuantumState,\n)\n\nCalculate the quantum state rotating ψ by an amount x about the axis defined by G.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_unitary!-Tuple{AbstractAnsatz, AbstractMatrix{<:Complex}}","page":"Home","title":"ADAPT.evolve_unitary!","text":"evolve_unitary!(\n    ansatz::AbstractAnsatz,\n    unitary::AbstractMatrix{<:Complex},\n)\n\nExtend a unitary by applying each generator in the ansatz (on the left).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_unitary!-Tuple{Any, Number, AbstractMatrix{<:Complex}}","page":"Home","title":"ADAPT.evolve_unitary!","text":"evolve_unitary!(\n    G::Generator,\n    θ::Parameter,\n    unitary::AbstractMatrix{<:Complex},\n)\n\nExtend a unitary by applying a single generator (on the left).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_unitary-Tuple{AbstractAnsatz, AbstractMatrix{<:Complex}}","page":"Home","title":"ADAPT.evolve_unitary","text":"evolve_state(\n    ansatz::AbstractAnsatz,\n    unitary::AbstractMatrix{<:Complex},\n)\n\nCalculate the matrix extending the given unitary by an ansatz (on the left).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.evolve_unitary-Tuple{Any, Number, AbstractMatrix{<:Complex}}","page":"Home","title":"ADAPT.evolve_unitary","text":"evolve_unitary(\n    G::Generator,\n    θ::Parameter,\n    unitary::AbstractMatrix{<:Complex},\n)\n\nCalculate the matrix extending the given unitary by a single generator (on the left).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.gradient!-Tuple{AbstractVector, AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.gradient!","text":"gradient!(\n    result::AbstractVector,\n    ansatz::AbstractAnsatz,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nFill a vector of partial derivatives with respect to each parameter in the ansatz.\n\nParameters\n\nresult: vector which will contain the gradient after calling this function\nansatz: the ADAPT state\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\nresult\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.gradient-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.gradient","text":"gradient(\n    ansatz::AbstractAnsatz,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nConstruct a vector of partial derivatives with respect to each parameter in the ansatz.\n\nParameters\n\nansatz: the ADAPT state\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\na vector of type typeof_energy(observable).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.is_converged-Tuple{AbstractAnsatz}","page":"Home","title":"ADAPT.is_converged","text":"is_converged(::AbstractAnsatz)\n\nCheck whether the sequence of generators in this ansatz are flagged as optimal.\n\nNote that this is a state variable in its own right;     its value is independent of the actual generators themselves,     but depends on all the protocols and callbacks     which brought the ansatz to its current state.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.is_optimized-Tuple{AbstractAnsatz}","page":"Home","title":"ADAPT.is_optimized","text":"is_optimized(::AbstractAnsatz)\n\nCheck whether the ansatz parameters are flagged as optimal.\n\nNote that this is a state variable in its own right;     its value is independent of the actual parameters themselves,     but depends on all the protocols and callbacks     which brought the ansatz to its current state.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.make_costfunction-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.make_costfunction","text":"make_costfunction(\n    ansatz::ADAPT.AbstractAnsatz,\n    observable::ADAPT.Observable,\n    reference::ADAPT.QuantumState,\n)\n\nConstruct a single-parameter cost-function f(x), where x is a parameter vector.\n\nNote that calling f does not change the state of the ansatz     (although actually it does temporarily, so this function is not thread-safe).\n\nParameters\n\nansatz: the ADAPT state\nobservable: the object defining the cost-function\nreference: an initial quantum state which the ansatz operates on\n\nReturns\n\nfn a callable function f(x) where x is a vector of angles compatible with ansatz\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.make_gradfunction!-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.make_gradfunction!","text":"make_gradfunction!(\n    ansatz::ADAPT.AbstractAnsatz,\n    observable::ADAPT.Observable,\n    reference::ADAPT.QuantumState,\n)\n\nConstruct a mutating gradient function g!(∇f, x), where x is a parameter vector.\n\nUsing this in place of make_gradfunction for optimization     will tend to significantly reduce memory allocations.\n\nNote that calling g! does not change the state of the ansatz     (although actually it does temporarily, so this function is not thread-safe).\n\nParameters\n\nansatz: the ADAPT state\nobservable: the object defining the cost-function\nreference: an initial quantum state which the ansatz operates on\n\nReturns\n\ng! a callable function g!(∇f,x)\n∇f and x are vectors of angles compatible with ansatz. The first argument ∇f is used to store the result; its initial values are ignored.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.make_gradfunction-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.make_gradfunction","text":"make_gradfunction(\n    ansatz::ADAPT.AbstractAnsatz,\n    observable::ADAPT.Observable,\n    reference::ADAPT.QuantumState,\n)\n\nConstruct a single-parameter gradient function g(x), where x is a parameter vector.\n\nNote that calling g does not change the state of the ansatz     (although actually it does temporarily, so this function is not thread-safe).\n\nParameters\n\nansatz: the ADAPT state\nobservable: the object defining the cost-function\nreference: an initial quantum state which the ansatz operates on\n\nReturns\n\ngd a callable function gd(x) where x is a vector of angles compatible with ansatz\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.optimize!-Tuple{AbstractAnsatz, Dict{Symbol, Any}, OptimizationProtocol, Any, Any, AbstractVector{<:AbstractCallback}}","page":"Home","title":"ADAPT.optimize!","text":"optimize!(\n    ansatz::AbstractAnsatz,\n    trace::Trace,\n    VQE::OptimizationProtocol,\n    H::Observable,\n    ψ0::QuantumState,\n    callbacks::CallbackList,\n)\n\nUpdate the parameters of an ansatz according to a given optimization protocol.\n\nParameters\n\nansatz: the ADAPT state\ntrace: a history of the ADAPT run thus far\nVQE: the optimization protocol (it doesn't have to be a VQE ^_^)\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\ncallbacks: a list of functions to be called just prior to updating the ansatz\n\nImplementation\n\nCallbacks must be called in each \"iteration\". The optimization protocol is free to decide what an \"iteration\" is,     but it should generally correspond to \"any time the ansatz is changed\". That's not a hard-fast rule, though -     for example, it doesn't necessarily make sense to call the callbacks     for each function evaluation in a linesearch.\n\nAny implementation of this method must be careful to obey the following contract:\n\nIn each iteration, update the ansatz parameters and      do whatever calculations you need to do. Fill up a data dict with as much information as possible. See the Callbacks module for some standard choices.\nCall each callback in succession, passing it the data dict. If any callback returns true, terminate without calling any more callbacks,      and discontinue the optimization.\nAfter calling all callbacks, check if the ansatz has been flagged as optimized. If so, discontinue the optimization.\nIf the optimization protocol terminates successfully without interruption by callbacks,      call set_optimized!(ansatz, true). Be careful to ensure the ansatz parameters actually are the ones found by the optimizer!\n\nStandard operating procedure is to let callbacks do all the updates to trace. Thus, implementations of this method should normally ignore trace entirely     (except in passing it along to the callbacks). That said, this rule is a \"style\" guideline, not a contract.\n\nThe return type of this method is intentionally unspecified,     so that implementations can return something helpful for debugging,     eg. an Optim result object. If the callbacks interrupt your optimization,     it may be worthwhile to check if they flagged the ansatz as converged,     and modify this return object accordingly if possible.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.partial-Tuple{Int64, AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.partial","text":"partial(\n    index::Int,\n    ansatz::AbstractAnsatz,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nThe partial derivative of a cost-function with respect to the i-th parameter in an ansatz.\n\nParameters\n\nindex: the index of the parameter to calculate within ansatz\nansatz: the ADAPT state\nobservable: the object defining the cost-function\nreference: an initial quantum state which the ansatz operates on\n\nReturns\n\na number of type typeof_energy(observable).\n\nImplementation\n\nTypically, generators apply a unitary rotation,     so the partial consists of a partial evolution up to the indexed generator,     then a \"kick\" from the generator itself, then a final evolution,     and a braket with the observable. But, different ansatze may have a different procedure.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.run!-Tuple{AbstractAnsatz, Dict{Symbol, Any}, AdaptProtocol, OptimizationProtocol, AbstractVector, Any, Any, AbstractVector{<:AbstractCallback}}","page":"Home","title":"ADAPT.run!","text":"run!(\n    ansatz::AbstractAnsatz,\n    trace::Trace,\n    ADAPT::AdaptProtocol,\n    VQE::OptimizationProtocol,\n    pool::GeneratorList,\n    H::Observable,\n    ψ0::QuantumState,\n    callbacks::CallbackList,\n)\n\nLoop between optimization and adaptation until convergence.\n\nThe ansatz and trace are mutated throughout,     so that if the user runs this method in a REPL,     she can terminate it (eg. by Ctrl+C) after however long,     and still have meaningful results.\n\nParameters\n\nansatz: the ADAPT state\ntrace: a history of the ADAPT run thus far\nADAPT: the ADAPT protocol\nVQE: the optimization protocol (it doesn't have to be a VQE ^_^)\npool: the list of generators to consider adding to the ansatz\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\ncallbacks: a list of functions to be called just prior to updating the ansatz\n\nReturns\n\ntrue iff the ansatz is converged, with respect to the given protocols and callbacks\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.set_converged!-Tuple{AbstractAnsatz, Bool}","page":"Home","title":"ADAPT.set_converged!","text":"set_converged!(::AbstractAnsatz, ::Bool)\n\nFlag the sequence of generators in this ansatz as optimal.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.set_optimized!-Tuple{AbstractAnsatz, Bool}","page":"Home","title":"ADAPT.set_optimized!","text":"set_optimized!(::AbstractAnsatz, ::Bool)\n\nFlag the ansatz parameters as optimal.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.typeof_energy-Tuple{Any}","page":"Home","title":"ADAPT.typeof_energy","text":"typeof_energy(::Observable)\n\nThe number type of a cost-function.\n\nThe method is so named because the typical cost-function is the expecation value     of a Hamiltonian, aka an energy.\n\nImplementation\n\nUsually a sub-type of AbstractFloat, and probably just about always Float64.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.typeof_parameter-Union{Tuple{AbstractAnsatz{F, G}}, Tuple{G}, Tuple{F}} where {F, G}","page":"Home","title":"ADAPT.typeof_parameter","text":"typeof_parameter(::AbstractAnsatz)\n\nThe number type of the variational parameters in this ansatz.\n\nI think this will always be a sub-type of AbstractFloat,     and almost always Float64.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.typeof_score-Tuple{AdaptProtocol}","page":"Home","title":"ADAPT.typeof_score","text":"typeof_score(::AdaptProtocol)\n\nThe number type of the score for each pool operator.\n\nImplementation\n\nUsually a sub-type of AbstractFloat, and probably just about always Float64.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate-Tuple{AbstractAnsatz, AdaptProtocol, OptimizationProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.validate","text":"validate(\n    ansatz::AbstractAnsatz,\n    adapt::AdaptProtocol,\n    vqe::OptimizationProtocol,\n    pool::GeneratorList,\n    observable::Observable,\n    reference::QuantumState;\n    kwargs...\n)\n\nValidate that ADAPT will work correctly with the given types.\n\nIt actually runs ADAPT,     so ensure your pool and observable are as simple as the types allow.\n\nThe mandatory arguments are exactly those found in the run! method,     except there is no trace.\n\nKeyword Arguments\n\nlabel: the name of the test-set (useful when validating more than one set of types).\ntolerance: the default tolerance for numerical tests\nevolution: special tolerance for the evolution test, or nothing to skip\nevaluation: special tolerance for the evaluation test, or nothing to skip\ngradient: special tolerance for the gradient test, or nothing to skip\nscores: special tolerance for the scores test, or nothing to skip\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_consistency-Tuple{AbstractAnsatz, AdaptProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.validate_consistency","text":"validate_consistency(\n    ansatz::AbstractAnsatz,\n    adapt::AdaptProtocol,\n    pool::GeneratorList,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nCheck that every core ADAPT function is internally consistent     (ie. different versions of the same function give consistent results).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_evaluation-Tuple{Any, Any}","page":"Home","title":"ADAPT.validate_evaluation","text":"validate_evaluation(\n    observable::Observable,\n    reference::QuantumState;\n    tolerance=1e-10,\n)\n\nCheck that observable evaluation matches brute-force matrix-vector results.\n\nThe difference between core ADAPT and brute-force     must have an absolute value within tolerance.\n\nThis function requires the following constructors to be defined:\n\nMatrix(::Observable)\nVector(::QuantumState)\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_evolution-Tuple{Any, Number, Any}","page":"Home","title":"ADAPT.validate_evolution","text":"validate_evolution(\n    generator::Generator,\n    angle::Parameter,\n    reference::QuantumState;\n    tolerance=1e-10,\n)\n\nCheck that generator evolution matches brute-force matrix-vector results.\n\nThe difference vector between core ADAPT and brute-force     must have a norm within tolerance.\n\nThis function requires the following constructors to be defined:\n\nMatrix(::Generator)\nVector(::QuantumState)\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_gradient-Tuple{AbstractAnsatz, Any, Any}","page":"Home","title":"ADAPT.validate_gradient","text":"validate_gradient(\n    ansatz::AbstractAnsatz,\n    observable::Observable,\n    reference::QuantumState;\n    tolerance=1e-10,\n)\n\nCheck that the gradient function matches the finite difference.\n\nThe difference vector between core ADAPT and brute-force     must have a norm within tolerance.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_runtime-Tuple{AbstractAnsatz, AdaptProtocol, OptimizationProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.validate_runtime","text":"validate_runtime(\n    ansatz::AbstractAnsatz,\n    adapt::AdaptProtocol,\n    vqe::OptimizationProtocol,\n    pool::GeneratorList,\n    observable::Observable,\n    reference::QuantumState;\n    verbose=true,\n)\n\nCheck that every core ADAPT function can run for the given types.\n\nIf verbose is true, this method also explicilty @time's everything,     to catch any super-obvious memory leaks when called manually.\n\nNote that this will run ADAPT for one iteration,     so ensure your pool and observable are as simple as the types allow.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.validate_scores-Tuple{AbstractAnsatz, AdaptProtocol, AbstractVector, Any, Any}","page":"Home","title":"ADAPT.validate_scores","text":"validate_score(\n    ansatz::AbstractAnsatz,\n    adapt::AdaptProtocol,\n    pool::GeneratorList,\n    observable::Observable,\n    reference::QuantumState;\n    tolerance=1e-10,\n)\n\nCheck that the score for each pool operator matches     the partial for that pool operator when added to a candidate ansatz.\n\nOf course this only makes sense when the score is the gradient,     which depends on the ADAPT protocol. But this is a common-enough choice to justify a standard method. Other ADAPT protocols may override this method, if desired.\n\nThe difference vector between core ADAPT and brute-force     must have a norm within tolerance.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.@runtime-Tuple{Any, Any}","page":"Home","title":"ADAPT.@runtime","text":"@runtime do_time, ex\n@runtime(do_time, ex)\n\nA macro to check that an expression evaluates without error,     optionally including an explicit test for runtime.\n\n\n\n\n\n","category":"macro"},{"location":"#Basics","page":"Home","title":"Basics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [\n    ADAPT.Basics,\n    ADAPT.Basics.Callbacks,\n    ADAPT.Basics.Operators,\n]","category":"page"},{"location":"#ADAPT.Basics.Ansatz","page":"Home","title":"ADAPT.Basics.Ansatz","text":"Ansatz{F<:Parameter,G<:Generator}(\n    parameters::Vector{F},\n    generators::Vector{G},\n    optimized::Bool,\n    converged::Bool,\n)\n\nA minimal ADAPT state.\n\nType Parameters\n\nF: the number type for the parameters (usually Float64 is appropriate.)\nG: the generator type. Any type will do, but it's best to be specific.\n\nParameter\n\nparameters: list of current parameters\ngenerators: list of current generators\noptimized: whether the current parameters are flagged as optimal\nconverged: whether the current generators are flagged as converged\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Ansatz-Tuple{Any, Any}","page":"Home","title":"ADAPT.Basics.Ansatz","text":"Ansatz(F, G)\n\nConvenience constructor for initializing an empty ansatz.\n\nParameters\n\nthe parameter type OR an instance of that type OR a vector whose elements are that type\nthe generator type OR an instance of that type OR a vector whose elements are that type\n\nThe easiest way to use this constructor is probably to prepare your generator pool first,     then call Ansatz(Float64, pool). But please note, the ansatz is always initialized as empty,     even though you've passed a list of generators in the constructor!\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.OptimOptimizer","page":"Home","title":"ADAPT.Basics.OptimOptimizer","text":"OptimOptimizer(method, options)\n\nParameters\n\nmethod: an optimizer object from the Optim package\noptions: an options object from the Optim package\n\nIMPORTANT: the callback attribute of options will be generated automatically         whenever ADAPT.optimize! is called, to insert dynamic callbacks.     If you provide your own callback in options, it will be ignored.     Use the ADAPT.Callback framework to gain extra behavior throughout optimization.     If this framework does not meet your needs,         you'll need to implement your own OptimizationProtocol.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.OptimOptimizer-Tuple{Symbol}","page":"Home","title":"ADAPT.Basics.OptimOptimizer","text":"OptimOptimizer(method::Symbol; options...)\n\nA convenience constructor to create OptimOptimizers without referring to Optim.\n\nParameters\n\nmethod: a symbol-ization of the Optim method\n\nKewyord Arguments\n\nYou can pass any keyword argument accepted either by     your Optim method's constructor, or by that of Optim.Options. If you try to pass a callback keyword argument, it will be ignored (see above).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.VanillaADAPT","page":"Home","title":"ADAPT.Basics.VanillaADAPT","text":"VanillaADAPT\n\nScore pool operators by their initial gradients if they were to be appended to the pool. Equivalently, score pool operators by the expectation value     of the commutator of the pool operator with the observable.\n\nThis protocol is defined for when the pool operators and the observable are AbstractPaulis. Note that fermionic operators are perfectly well-represented with AbstractPaulis.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.__make__costate-Tuple{Any, Any, Any}","page":"Home","title":"ADAPT.Basics.__make__costate","text":"__make__costate(G, x, Ψ)\n\nCompute ∂/∂x exp(ixG) |ψ⟩.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.__make__costate-Tuple{Array{PauliOperators.ScaledPauli{N}, 1} where N, Any, Dict{PauliOperators.KetBitString{N}} where N}","page":"Home","title":"ADAPT.Basics.__make__costate","text":"__make__costate(G::ScaledPauliVector, x, Ψ)\n\nCompute ∂/∂x exp(ixG) |ψ⟩.\n\nDefault implementation just applies -iG to Ψ then evolves. That's fine as long as the evolution is exact. But evolution is not exact if G is a ScaledPauliVector containing non-commuting terms. In such a case, the co-state must be more complicated.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.partial-Tuple{Int64, AbstractAnsatz, Union{Array{PauliOperators.ScaledPauli{N}, 1} where N, PauliOperators.Pauli, PauliOperators.PauliSum, PauliOperators.ScaledPauli}, Any}","page":"Home","title":"ADAPT.partial","text":"partial(\n    index::Int,\n    ansatz::AbstractAnsatz,\n    observable::Observable,\n    reference::QuantumState,\n)\n\nThe partial derivative of a cost-function with respect to the i-th parameter in an ansatz.\n\nThe ansatz is assumed to apply a unitary rotation exp(-iθG),     where G is the (Hermitian) generator,     and generators with a lower index are applied to the state earlier. Ansatz sub-types may change both behaviors.\n\nParameters\n\nindex: the index of the parameter to calculate within ansatz\nansatz: the ADAPT state\nH: the object defining the cost-function\nψ0: an initial quantum state which the ansatz operates on\n\nReturns\n\na number of type typeof_energy(observable).\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.Callbacks","page":"Home","title":"ADAPT.Basics.Callbacks","text":"Callbacks\n\nA suite of basic callbacks for essential functionality.\n\nExplanation\n\nThe final argument of the adapt!, optimize! and run! methods     calls for a vector of Callbacks. These are callable objects extending behavior at each iteration or adaptation     (or both; see the AbstractCallback type documentation for more details).\n\nThe callback is passed a data object     (aka. a Dict where the keys are Symbols like :energy or :scores),     in addition to the ADAPT state and all the quantum objects. Callbacks may be as simple as displaying the data,     or as involved as carefully modifying the quantum objects to satsify some constraint.\n\nEach callback in this module can be categorized as one of the following:\n\nTracers: update the running trace with information passed in data\nPrinters: display the information passed in data to the screen or to a file\nStoppers: flag the ADAPT state as converged, based on some condition\n\nIn particular, Stoppers are the primary means of establishing convergence in Vanilla ADAPT. They do this by flagging the ADAPT state as converged,     which signals to the run! function that it can stop looping once this round is done. Alternatively, though none of the basic callbacks in this module do so,     you amy implement a callback that returns true based on some condition. This signals an instant termination, regardless of convergence.\n\nJust to reiterate, Stoppers are the primary means of establishing convergence. If you don't include any callbacks, the run! call may not terminate this century!\n\nCallback Order\n\nCallback order matters. Using the callbacks in this module, I recommend the order listed above     (Tracers, then Printers, then Stoppers).\n\nThe first callback in the list gets dibs on mutating the trace or the ADAPT state,     which could change the behavior of subsequent callbacks. For example, the basic Printer inspects the trace to infer the current iteration,     so it naturally follows the Tracer.     (although the Printer knows to skip this part if there is no Tracer). Some Stoppers (eg. SlowStopper, FloorStopper)     inspect the trace to decide whether energy has converged,     so the \"latest\" energy should already be logged. Therefore, these too should follow the Tracer.\n\nPlease note that, because the callbacks are called prior to actually updating the ansatz,     the Tracer will usually log one last round of updates     which are not actually reflected in the ansatz. The only times this does not happen are if convergence is flagged by the protocol itself     rather than a Stopper callback (eg. all scores are essentially zero),     which is probably never. ^_^ This behavior seems fine, even desirable, to me, but if you'd like to avoid it,     you could implement a Stopper which explicitly terminates by returning true     (rather than merely flagging the ansatz as converged, like basic Stoppers),     and listing that Stopper prior to the Tracer.\n\nStandard keys\n\nThe actual keys used in the data argument are determined by the protocol,     so you may design custom callbacks to make use of the data in your custom protocols.\n\nHowever, for the sake of modularity, it is worth keeping keys standardized when possible. Here is a list of recommended keys.\n\nReserved keys\n\n:iteration: iteration count over all optimizations\n:adaptation: which iteration an adaptation occurred\n\nThese keys are not part of data but are used in the running trace.\n\nStandard keys for adapt!\n\n:scores: vector of scores for each pool operator\n:selected_index: index in the pool of the operator ADAPT plans to add\n:selected_generator: the actual generator object ADAPT plans to add\n:selected_parameter: the parameter ADAPT plans to attach to the new generator\n\nProtocols which add multiple generators in a single adaptation     may still use these same keys, replacing the values with vectors.\n\nStandard keys for optimize!\n\n:energy: the result of evaluating the observable. Required for some Stoppers\n:g_norm: the norm of the gradient vector (typically ∞ norm, aka. largest element)\n:elapsed_iterations: the number of iterations of the present optimization run\n:elapsed_time: time elapsed since starting the present optimization run\n:elapsed_f_calls: number of function calls since starting the present optimization run\n:elapsed_g_calls: number of gradient calls since starting the present optimization run\n\n\n\n\n\n","category":"module"},{"location":"#ADAPT.Basics.Callbacks.FloorStopper","page":"Home","title":"ADAPT.Basics.Callbacks.FloorStopper","text":"FloorStopper(threshold::Energy, floor::Energy)\n\nConverge once the energy has gotten close enough to some target value.\n\nCalled for adapt! only. Requires a preceding Tracer(:energy).\n\nParameters\n\nthreshold: maximum energy difference before convergence\nfloor: the target value\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.ParameterPrinter","page":"Home","title":"ADAPT.Basics.Callbacks.ParameterPrinter","text":"ParameterPrinter(; io=stdout, adapt=true, optimize=false, ncol=8)\n\nPrint the current ansatz parameters as neatly and compactly as I can think to.\n\nParameters\n\nio: the IO stream to print to\nadapt: print parameters at each adaptation\noptimize: print parameters at each optimization iteration\nncol: number of parameters to print in one line, before starting another\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.ParameterStopper","page":"Home","title":"ADAPT.Basics.Callbacks.ParameterStopper","text":"ParameterStopper(n::Int)\n\nConverge once the ansatz reaches a certain number of parameters.\n\nCalled for adapt! only.\n\nParameters\n\nn: the minimum number of parameters required for convergence\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.ParameterTracer","page":"Home","title":"ADAPT.Basics.Callbacks.ParameterTracer","text":"ParameterTracer()\n\nAdd the ansatz parameters to the running trace, under the key :parameters.\n\nOnly compatible when following a Tracer including :selectedindex. This is no great handicap since the principal point of this is     to be able to reconstruct an ansatz,     and you'll need the :selectedindex for that also. ;)\n\nParameters are stored in a matrix. Each column is associated with an angle in the ansatz     (vanilla protocol sets the first column as the first parameter added to the ansatz     and the first one applied to the reference state). Each row gives the optimized parameters for the corresponding ADAPT iteration.\n\nThe adapt callback is responsible for adding a new row     (vanilla protocol is to initialize with the previously optimized parameters),     and for padding previous rows with zeros. The optimization callback is responsible for keeping the last row updated     with the currently-best parameters for this choice of parameters.\n\nStandard practice is to include the ParameterTracer AFTER the regular Tracer,     but BEFORE any ADAPT convergence Stoppers. Thus, the parameter matrix INCLUDES columns for the last-selected parameter(s). Standard practice for reconstructing an optimized ansatz of a converged trace     is to look at the PENULTIMATE row.\n\nPlease note that the default implementation of this callback is unsuitable     (or at least the matrix requires some post-processing)     if the AdaptProtocol reorders parameters,     or even simply inserts new parameters anywhere other than the end,     or even (currently) if parameters aren't initialized to zero,     or even (currently) if it adds more than one parameter at once. (NOTE: These last two are easily adjusted     but will require a more complex trace precondition.) If you need a parameter tracer for such protocols,     you'll need to dispatch to your own method.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.Printer","page":"Home","title":"ADAPT.Basics.Callbacks.Printer","text":"Printer([io::IO=stdout,] keys::Symbol...)\n\nPrint selected data keys at each iteration or adaptation.\n\nThe keys arguments are passed in the same way as Tracer;     see that method for some examples. Unlike Tracer, the first argument can be an IO object,     which determines where the printing is done. By default, it is the standard output stream, ie. your console,     or a file if you are redirecting output via >. The io argument allows you to explicitly write to a file,     via Julia's open function.\n\nIf a key is not present in data, it is ignored. Thus, the same list of keys is used for calls from adapt! and optimize!,     so long as keys do not overlap (which should be avoided)!\n\nThe keys :iteration and :adaptation are treated specially. These keys will not appear directly in data,     and they should not be included in keys. If the trace contains these keys (ie. if a Tracer callback was also included),     they are used as \"section headers\". Otherwise, they are skipped.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.ScoreStopper","page":"Home","title":"ADAPT.Basics.Callbacks.ScoreStopper","text":"ScoreStopper(threshold::Score)\n\nConverge if all scores are below a certain threshold.\n\nCalled for adapt! only.\n\nParameters\n\nthreshold: the maximum score\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.Serializer","page":"Home","title":"ADAPT.Basics.Callbacks.Serializer","text":"Serializer(; ansatz_file=\"\", trace_file=\"\", on_adapt=false, on_iterate=false)\n\nSerialize the current state so that it can be resumed more easily.\n\nPlease note that robust serialization depends heavily on version control;     if the definition of a serialized type has changed since it was serialized,     it is very, very difficult to recover. Thus, serialization of this nature should be considered     somewhat transient and unreliable. It's good for restarting when your supercomputer crashes unexpectedly mid-job,     but not so good for long-term archival purposes.\n\nParameters\n\nansatz_file: file to save ansatz in (\"\" will skip saving ansatz)\ntrace_file: file to save trace in (\"\" will skip saving trace)\non_adapt: whether to serialize on adaptations\non_iterate: whether to serialize in every optimization iteration\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.SlowStopper","page":"Home","title":"ADAPT.Basics.Callbacks.SlowStopper","text":"SlowStopper(threshold::Energy, n::Int)\n\nConverge if all energies in the past n iterations are within a certain range.\n\nCalled for adapt! only. Requires a preceding Tracer(:energy).\n\nParameters\n\nthreshold: maximum energy range before convergence\nn: number of recent adaptations to check\nThis function will not flag convergence       before at least n adaptations have occurred.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Callbacks.Tracer","page":"Home","title":"ADAPT.Basics.Callbacks.Tracer","text":"Tracer(keys::Symbol...)\n\nAdd selected data keys at each iteration or adaptation to the running trace.\n\nExamples\n\nTracer(:energy)\n\nIncluding this callback in a run! call will fill the trace argument     with the energy at each optimization iteration,     as well as noting in which iteration each adaptation occurred. I cannot think of a circumstance when you will not want to trace at least this much.\n\nTracer(:energy, :scores)\n\nThis example shows the syntax to keep track of multiple data keys:     just list them out as successive arguments of the same Tracer. Do NOT include multiple instances of Tracer in the same run,     or you will record twice as many iterations as actually occurred! The ParameterTracer is a distinct type and is safe to use with Tracer.\n\nOther Notes\n\nIf a key is not present in data, it is ignored. Thus, the same list of keys is used for calls from adapt! and optimize!,     so long as keys do not overlap (which should be avoided)!\n\nThe keys :iteration and :adaptation are treated specially. These keys will not appear directly in data,     and they should not be included in keys.\n\nThe :iteration value will simply increment with each call from optimize!. The :adaptation value will be set to the most recent :iteration value.\n\nI highly recommend including at minimum Tracer(:energy)     with every single ADAPT run you ever do.\n\n\n\n\n\n","category":"type"},{"location":"#ADAPT.Basics.Operators","page":"Home","title":"ADAPT.Basics.Operators","text":"Operators\n\nA suite of common operators, especially useful for constructing operator pools.\n\nTODO:     I haven't decided yet whether observables should live here or not.     If they do, I'll want to standardize the interface somehow.     In particular, the interface with pyscf for molecules is rather hazy.     I think we need a separate package which is a Julia wrapper for openfermion.     Then observables will generally be input as qubit operators from that package,         or perhaps we have a simple method that converts qubit operators to PauliSums,         so we have better control over the arithmetic being performed.     In any case, though I may evict them someday,         standard lattice systems like Hubbard and Heisenberg, not requiring openfermion,         may inhabit this module for the time being.\n\n\n\n\n\n","category":"module"},{"location":"#ADAPT.Basics.Operators.hubbard_hamiltonian-Tuple{Int64, Any, Any}","page":"Home","title":"ADAPT.Basics.Operators.hubbard_hamiltonian","text":"hubbard_hamiltonian(L::Int, U, t; pbc=false)\n\nConvenience constructor for a 1D nearest-neighbor Hubbard model with L sites.\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.Operators.hubbard_hamiltonian-Union{Tuple{T}, Tuple{Matrix{T}, Any, Any}} where T","page":"Home","title":"ADAPT.Basics.Operators.hubbard_hamiltonian","text":"hubbard_jw(graph::Array{T,2}, U, t)\n\nA Hubbard Hamiltonian in the Jordan-Wigner basis.\n\nCopied shamelessly from Diksha's ACSE repository.\n\nParameters\n\ngraph: an adjacency matrix identifying couplings. Must be symmetric.\nU: Coulomb interaction for all sites\nt: hopping energy for all couplings\n\nReturns\n\nPauliOperators.PauliSum: the Hamiltonian\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.Operators.qubitexcitation-Tuple{Int64, Int64, Int64}","page":"Home","title":"ADAPT.Basics.Operators.qubitexcitation","text":"qubitexcitation(n::Int, i::Int, k::Int)\nqubitexcitation(n::Int, i::Int, j::Int, k::Int, l::Int)\n\nQubit excitation operators as defined in Yordanov et al. 2021.\n\nNote that Yordanov's unitaries are defined as exp(iθG) rather than exp(-iθG),     so variational parameters will be off by a sign.\n\nParameters\n\nn: total number of qubits\ni,j,k,l: qubit indices as defined in Yordanov's paper.\n\nReturns\n\nPauliOperators.ScaledPauliVector: the qubit excitation operator\nNote that all Pauli terms in any single qubit excitation operator commute,       so the ScaledPauliVector representation is \"safe\".\n\n\n\n\n\n","category":"method"},{"location":"#Other-Modules","page":"Home","title":"Other Modules","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [\n    ADAPT.OptimizationFreeADAPT,\n    ADAPT.OverlapADAPT,\n]","category":"page"},{"location":"#ADAPT.OptimizationFreeADAPT.OptimizationFree","page":"Home","title":"ADAPT.OptimizationFreeADAPT.OptimizationFree","text":"OptimizationFree\n\nThe optimization protocol which just doesn't do anything.\n\nThere are no iterations, so there is no reason to callback. Contract obliged!\n\n\n\n\n\n","category":"type"},{"location":"#Base.Matrix-Tuple{ADAPT.OverlapADAPT.Infidelity}","page":"Home","title":"Base.Matrix","text":"Matrix(infidelity)\n\nConvert an infidelity to a matrix.\n\nThis implementation assumes:\n\nThe target state infidelity.Φ can be cast to a vector.\nThe reference state in evaluate(infidelity, reference) is always normalized.\n\n\n\n\n\n","category":"method"},{"location":"#MyPauliOperators","page":"Home","title":"MyPauliOperators","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"These methods should not be considered part of \"ADAPT\",     but rather, destined for the PauliOperators.jl package. The only reason I document them here is that     the doc builder is configured to throw an error     if any doc strings aren't included in the documentation...","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [\n    ADAPT.Basics.MyPauliOperators,\n]","category":"page"},{"location":"#ADAPT.Basics.MyPauliOperators.cis!-Tuple{AbstractVector, PauliOperators.FixedPhasePauli, Any}","page":"Home","title":"ADAPT.Basics.MyPauliOperators.cis!","text":"TODO: VERY SPECIFICALLY ASSERT that pauli xz=00 is to be interpreted as I,                                     pauli xz=10 is to be interpreted as X,                                     pauli xz=01 is to be interpreted as Z,                                 and pauli xz=11 is to be interpreted as Y,                                 despite the last usually being interpreted as iY.     Also clear this definition with Nick before putting it in his package...\n\n\n\n\n\n","category":"method"},{"location":"#ADAPT.Basics.MyPauliOperators.measure_commutator-Tuple{Union{Array{PauliOperators.ScaledPauli{N}, 1} where N, PauliOperators.AbstractPauli, PauliOperators.PauliSum}, Union{Array{PauliOperators.ScaledPauli{N}, 1} where N, PauliOperators.AbstractPauli, PauliOperators.PauliSum}, Union{Dict{PauliOperators.KetBitString{N}} where N, AbstractVector}}","page":"Home","title":"ADAPT.Basics.MyPauliOperators.measure_commutator","text":"measure_commutator(\n    A::AnyPauli,\n    B::AnyPauli,\n    Ψ::Union{SparseKetBasis,AbstractVector},\n)\n\nCalculate the expectation value of the commutator, ie. ⟨Ψ|[A,B]|Ψ⟩.\n\nTODO: There could be a place for this in PauliOperators,         but it would need to be carefully fleshed out type by type.     A and B needn't be Hermitian in general (though I assume they are here),         so my intuition is rather lacking.\n\n\n\n\n\n","category":"method"},{"location":"#Base.:*-Union{Tuple{N}, Tuple{PauliOperators.PauliSum{N}, Array{PauliOperators.ScaledPauli{N}, 1}}} where N","page":"Home","title":"Base.:*","text":"Cross-type multiplication. Best to discourage ever doing this operation. Needed for a lazy commutator, but not necessarily needed long-term. We'll return pauli sum for now.\n\n\n\n\n\n","category":"method"},{"location":"#Base.:*-Union{Tuple{T}, Tuple{N}, Tuple{Array{PauliOperators.ScaledPauli{N}, 1}, Dict{PauliOperators.KetBitString{N}, T}}} where {N, T}","page":"Home","title":"Base.:*","text":"Of course this one is missing... ^_^ Note strict typing in out, because Paulis themselves are strictly typed.\n\n\n\n\n\n","category":"method"},{"location":"#Base.adjoint-Tuple{Array{PauliOperators.ScaledPauli{N}, 1} where N}","page":"Home","title":"Base.adjoint","text":"TODO: Consult with Nick before adding this definition to PauliOperators.\n\nI hesitate for two reasons:\n\nIt is not \"lazy\". It allocates a new array.  Not unprecedented but not ideal.  Not sure the proper way to make it lazy.\nColumn vector adjoint should properly be a row vector, rather than reversed.  Can't think of why we'd ever use ScaledPauliVector as a column vector,      but its data type is so, properly.\n\nBut, this definition achieves desired polymorphism in evolving by ScaledPauliVector,     so if Nick okays it, I'm happy with it. The alternative is a dedicated unevolve function with a tedious special case     for unevolving ansatze whose generators are ScaledPauliVector...\n\n\n\n\n\n","category":"method"},{"location":"#Base.adjoint-Tuple{Dict{PauliOperators.KetBitString{N}} where N}","page":"Home","title":"Base.adjoint","text":"TODO: This adjoint is not strictly \"lazy\". But I don't think anyone will care.\n\n\n\n\n\n","category":"method"}]
}
